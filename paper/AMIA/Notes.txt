Introduction:
==============
1) Natural language processing (NLP) techniques can extract variables from free-text clinical records important for medical informatics applications performing decision support, quality assurance, and biosurveillance. 

2) Clinical narrative records contain much useful information. However, most clinical narratives are in the form of fragmented English free text, showing the characteristics of a clinical sublanguage. This makes their linguistic processing, search, and retrieval challenging. 1 Traditional natural language processing (NLP) tools are not designed for the fragmented free text found in narrative clinical records; therefore, they do not perform well on this type of data. 2 Limited access to clinical records has been a barrier to the widespread development of medical language processing (MLP) technologies. In the absence of a standardized, publicly available ground truth that encourages the development of MLP systems and allows their head-to-head comparison, successful MLP efforts have been limited, e.g., MedLEE 3 and Symtxt. 4 A few MLP systems have been developed, 5 and such efforts have successfully shown the usefulness of MLP in clinical settings. 6-8

To improve the availability of clinical records and to contribute to the advancement of the state of the art in MLP, within the i2b2 (Informatics for Integrating Biology to the Bedside) project, the authors de-identified and released a set of clinical records from Partners HealthCare. These records provided the basis for the development of ground truth for two challenge questions:

a) Automatic de-identification of clinical data, i.e., de-identification challenge.
b) Automatic evaluation of the smoking status of patients based on medical records, i.e., smoking challenge.

3) The proliferation and ubiquitous accessibility of health-related textual data in electronic form requires computational support for content tracking and management. The field of information retrieval has a long-standing tradition in investigating content-sensitive document filters, which determine relevant documents relative to user queries (cf. [1] for a survey from a medical perspective). The user may then check these documents and extract intellectually the desired information from them.

In the past decade, research efforts have also been targeted at the automatic extraction of relevant information directly from document sources. Ideally, this approach should remove the user from the burden to read and understand documents, since all relevant information is already harvested from them and accessible by querying a data or knowledge base (cf. [2] for an overview). While substantial progress has been made already (cf. various prototypes in the medical domain such as LSP [3], MedLEE [4], Menelas[5], Recit[6], or Clarit[7]), current information extraction (IE) systems still suffer from various weaknesses.

First, their range of understanding is bounded by rather simple and limited domain knowledge. The templates these systems are supplied with allow only factoid information about particular, a priori chosen entities (diseases, findings, viruses, severity degrees etc.) to be gathered from the analyzed documents. Also, these knowledge sources are considered to be entirely static. Accordingly, when the focus of interest of a user shifts to (facets of) a topic not considered so far, new templates must be supplied or existing ones must be updated manually. In any case, for a modified or an enhanced set of templates, the analysis has to be rerun for the entire document collection. Templates also provide either no or severely constrained inferencing capabilities to reason about the template fillers—hence, their understanding depth is low. Finally, the potential of IE systems for dealing with textual phenomena is rather weak, if it is available at all. Reference relations spanning several sentences, however, may cause invalid knowledge base structures to emerge so that incorrect information may be retrieved or inferred (cf. Section 2.2).

With the SynDiKATe system family, we are addressing these shortcomings and aim at a more sophisticated level of information extraction from real-world texts. The source documents we deal with are currently taken from two domains, viz. test reports from the information technology (IT) domain (itSynDiKATe[8]) and pathology findings reports (medSynDiKATe[9]). medSynDiKATe is designed to acquire from each input text a maximum number of descriptive factoid propositions (‘The findings correspond to an adenocarcinoma’), as well as subjective evaluative assertions (‘The findings correspond to a severe chronical gastritis’), the latter based on a model of dimensional and comparative reasoning described in [10]. Hence, our primary goal is to extract conceptually deeper and inferentially richer forms of relational information than that found by state-of-the-art IE systems. Also, rather than restricting natural language processing intentionally to few target templates, we here present an open system architecture for information extraction where the depth of text understanding is constrained only by the accidental limits of available knowledge sources, the domain ontology, in particular.

To achieve this goal, several requirements with respect to language processing proper have to be fulfilled. As most of the IE systems, we require our parser to be robust to grammatical and conceptual underspecification and ill-formed input (cf. the protocols in [11]). Unlike many of them, our parsing system is particularly sensitive to the treatment of a broad range of textual reference relations as established by various forms of anaphora [12]. Furthermore, since SynDiKATe systems rely on a knowledge-rich infrastructure, particular care is taken to provide expressive knowledge repositories on a larger scale. Since there are inherent limits to the manual supply of grammatical and conceptual knowledge, we are currently exploring two alternatives to automate these processes. First, we automatically enhance the set of already given knowledge templates through incremental concept learning routines [13]. Our second approach makes use of the large body of knowledge that has already been assembled in medical terminologies (e.g. the UMLS). That knowledge is automatically transformed into a description logics format and, after interactive debugging and refinement, integrated into a comprehensive medical knowledge base [14].

4) There have been a number of efforts to extract useful data from discharge summaries. Friedman’s group at Columbia have been prominent in using a detailed linguistic approach to natural language processing with their MedLEE parser to interpret discharge summaries and extract diseases and other information from them1,2,3. Another effort used triggering words to look for adverse events, with less success because of the variety of ways these events may be expressed4 . Discharge summaries are organized into a number of sections. Usually included among these sections are the “past medical history” and possibly the “discharge diagnoses”. These sections are lists of the diseases and associated procedures. The function of the program is to extract those diseases and procedures and code them. With the addition of SNOMED-CT to the UMLS, there is great incentive to use this resource to code the diseases into this widely recognized vocabulary5 . The MetaMap program available from the NLM is a tool for coding phrases into the UMLS that provides a standard for comparison6 . There are a number of problems that make disease extraction challenging. The diseases are found in sections with a variety of names, separated in several ways. The disease statements may have additional descriptive text. The diseases themselves may be more specific than is codable in a single code or there may be no code for the disease as described. We have developed a program that handles these problems sufficiently to extract and code almost all of the diseases in a training sample of 23 discharge summaries of patients in intensive care units of a teaching hospital. 

5) Electronic health records (EHR) have become a pervasive healthcare information technology. They replaced paper-based systems in many healthcare organizations and garnered rich health data, which hold great value for reuse. As The American Medical Informatics Association (AMIA) stated at its website, (http://www2.amia.org/inside/initiatives/healthdata/): “Secondary use of health data can enhance healthcare experiences for individuals, expand knowledge about disease and appropriate treatments, strengthen understanding about the effectiveness and efficiency of our healthcare systems, support public health and security goals, and aid businesses in meeting the needs of their customers”.

6) A regular expression is a sequence of characters describing a pattern of text. It is a standard technique supported by most programming languages (eg, .NET, Java, Python, Perl, Ruby, AWK, and Tcl). Many prior natural language processing (NLP) studies in the clinical domain have used regular expressions in designing their NLP solutions.1–12 These regular expressions are typically created by software developers working with domain experts. Since there is no standard way to generate or test regular expressions, their maintenance and extension is a challenge.

Given the wide use of regular expressions, computer algorithms have been developed to automatically discover them from training text samples. A key challenge in learning regular expressions is the huge search space of candidates since each text string may be matched by numerous expressions. To reduce the search space and select the valid expressions, two main learning approaches have been employed (figure 1). The top-down approach often starts with domain experts supplying seed patterns; they are then transformed or modified until satisfying predefined evaluation metrics have been achieved. This approach has been used by Xie et al, Li et al, Babbar and Singh, and Brauer et al to learn email,13 ,14 URL,13 ,14 software name,13 ,15 notebook name,15 course number,13 phone number,13 ,15 ,16 invoice number,15 and date–time16 patterns. Top-down versus bottom-up approaches in automated regular expression generation.

The bottom-up approach starts by finding similarities or patterns among textual data that are then generalized to build regular expressions (figure 1). For example, Prasse et al17 used the bottom-up approach to discover regular expressions from batches of email and campaign message templates. They tested the method on predefined input batches (5–50 instances per batch). Meng et al18 have employed multiple sequence alignment algorithms to detect the sequential patterns in clinical text. The identified patterns could potentially be used for text classification, although the study itself did not perform classification procedures.

One major issue with existing regular expressions learning algorithms is the generalizability. The performance of the top-down approach is dependent on seed patterns, the creation of which is not automated. In the example of figure 1, patterns like ‘quit smoking’ or ‘smokes \d+packs a day’ are manually generated. The bottom-up approach is totally automated, though the algorithms described in the literature are still task-specific. For instance, the sample data in figure 1 are not pre-clustered batches as the data in Prasse et al's study.17 Ideally, a generalizable expression-based classifier would behave just like feature-based classifiers that learn directly from annotated data and generate labels for unseen samples.

We present a general purpose regular expression learning algorithm in this paper, called the regular expression discovery (RED). The algorithm employs a bottom-up approach that first conducts pairwise alignment to identify sequential similarity and then constructs regular expressions.

We created two classifiers that use the RED generated expressions. The RED algorithm was tested on two different clinical classification tasks. In addition, we compared the RED performance with the popular support vector machine (SVM) algorithm using bag of word (BOW) features. 

7) With the rapid adoption of Electronic Health Records (EHRs), it is desirable to harvest the information and knowledge in EHRs to support automated systems at point-of-care and to enable secondary use of EHRs for clinical and translational research. Much of the EHR data is in free text form. Comparing to structured data, free text is a more conventional way in the health care environment to express concepts and events. The free text records are generated by automated or manual transcription of dictation recordings and direct entry by the care providers. However, free text is very challenging for searching, summarization, decision-support, or statistical analysis. To reduce medical errors, improve health care quality, and enable secondary use of EHRs, information extraction (IE), which structures and encodes clinical information stored in free text, is necessary. Approaches to IE are based on either symbolic techniques (e.g., NegEx1 ) or statistical machine learning. Clinical IE applications using symbolic techniques can be cumbersome to implement and may lack portability. IE applications based on statistical NLP techniques require annotated examples and are easy to apply but may not accurately capture the relationships among words in a document such as negation. As pointed out by Wagholikar et al.2 and Chapman et al.3 , when a task involves a specific subdomain (as in preventive care decision support of cervical cancer) or a limited number of named entities (as in detection of influenza), sublanguage analysis detecting subdomain semantics combined with contextual information detection and expert knowledge engineering is a viable approach. Through a collaboration with IBM, Mayo Clinic has developed a system called Mayo Clinic Information Extraction system used to process all clinical notes available in the Enterprise Data Trust (EDT)4 . A variation of this system named clinical Text Analysis and Knowledge Extraction System (cTAKES) has been released under an Apache open source license through the open health NLP consortium (OHNLP)5 . Additional modules have been implemented within cTAKES recently including a smoking status identification module6 , a refined drug information extraction module, and a side effect extraction module 7 . Here, we report a new IE framework for extracting named entities and their corresponding contextual information under cTAKES that is purely knowledge-driven. We will assume named entities are handcrafted based on expert knowledge with or without sublanguage analysis. We test the framework through implementing a couple of NLP components for cohort identification. In the following, we describe background information of the modules in the IE framework. We then describe the system in detail followed by case studies on two eMERGE phenotypes to evaluate the IE framework 

In this section, we describe the background information about section and contextual information detection. We then describe two Electronic Medical Records and Genomics (eMERGE) phenotypes used in evaluating the IE framework. Section Detection - Clinical notes are often divided into sections, or segments, such as "history of present illness" or "past medical history." These sections may have subsections as well, such as the "cardiovascular exam" section of the "physical exam." One can gain greater understanding of clinical notes by recognition of the section in which a  name entity locates. For instance, both "past medical history" and "family medical history" sections can contain a list of diseases, but the context information is very different. Section tagging is an early step in NLP applications for clinical notes. One such system for section detection is SecTag which recognizes section headers through terminology lookup, machine learning, spelling correction, and scoring techniques8,9 . The terminology used by SecTag provides a list of concepts that represent particular section headings by extending Logical Observation Identifiers Names and Codes (LOINC®). Each concept in SecTag has one or more synonyms that may be used to specify a section in an actual note. Contextual Information – Contextual information of a condition includes: negation (is the condition negated or not), temporality (historical or current), and experiencer (who has the condition). ConText is a system that determines the values for the above three contextual properties of a clinical condition 10 . The contextual property negation specifies the status of the clinical existence of a condition. The default value of this property is affirmed. If a clinical condition occurs within the scope of a trigger term for negation, ConText will change the default value to negative. For example, in the sentence ‘‘The patient denies any nausea,” the value of negation for the condition ‘‘nausea” will be negated. 

System Description
As mentioned, our IE framework is knowledge-driven and developed under Unstructured Information Management Architecture (UIMA) which has been widely adopted to implement systems for processing unstructured content17 . Different UIMA components can be combined to create a pipeline of modular tools, and all components use the same data structure, the Common Analysis Structure (CAS). In general, a UIMA pipeline consists of three types of components, a Collection Reader for accessing the documents from a source and initializing a CAS object for each document. The analysis of the documents is performed by Analysis Engines that add annotations to the CAS objects. Finally, CAS Consumers are used for final processing, e.g., for exporting the annotated information to a format that can be used for downstream analysis (e.g., building machine learning classifiers). Figure 1 shows an overall architecture of the system as well as an example of knowledge needed. After initializing a document to a CAS object, sentences in the document are detected, tokens and chunks are generated. Section detection is then performed so that we can specify sections to extract information. The default section dictionary is the SecTag terminology supplemented with section synonyms acquired from i2b2 2010 NLP corpora18 . The information extracted can be of two types: concept mention (CM) or matching (MATCH) where the context information detection (adapted from ConText) is performed only on all CM instances. There are three knowledge  components: regular expression, normalization and match rule, for executing the IE engine where the regular expression component specifies patterns used in the match rule components and normalization target is to specify the target form of a regular expression. For example, “severe occlusion” and “high-grade occlusion” in diagnosis or impression sections will be matched instances and they are normalized to “pos_occlusion”. Those knowledge components are externalized from the IE engine to facilitate customizability and maintenance.   

8) Electronic medical records (EMR) are increasingly being used to document and store large amounts of clinical information [1]. The widespread adoption of EMR systems has provided vast data sources which can facilitate clinical research and studies to ultimately improve healthcare quality [2–4]. However, the ability to efficiently and accurately extract meaningful data from electronic health records is challenging as a significant portion of clinical information is stored in unstructured, free text. Therefore, a manual review of this data is often necessary which can be time-consuming, error prone, and costly [5].

Natural language processing (NLP) is a field of computer-based methods aiming to facilitate the processing of the human (natural) language [6]. NLP is an invaluable tool to extract and process information residing in the natural language format into a more structured layout for research [7]. Using pre-defined computer algorithms, NLP systems can be automated to parse textual information and search for key words and phrases in order to extract pertinent clinical data. NLP systems can rapidly analyze large clinical datasets and deliver real-time outcomes for various research applications and healthcare outcomes analyses.

At present, little is known regarding the integration of bioinformatics with programs such as NLP in the clinical arena. There is a paucity of research on the application of NLP systems in clinical medicine, especially within the field of urology. Our study determined the ability of an NLP program to identify patients with newly diagnosed prostate cancer in order to establish a database to study the effect of prostate cancer treatments on quality of life outcomes. For our proposed study, it was vital to obtain baseline quality of life measurements at the time of prostate cancer diagnosis. Thus, an efficient and timely method was necessary to identify patients with new diagnoses of prostate cancer, before treatment was commenced. We therefore implemented an NLP system to extract pertinent pathologic data from electronic health records at the time of diagnosis. In the current study, we specifically assess the validity of our NLP program to accurately identify patients with prostate cancer after biopsy and to retrieve pertinent pathologic information from their EMR.

Materials and methods
This study was a cross-sectional analysis of a prospectively collected, institutional review board-approved database including patients from the Southern California Kaiser Permanente Medical Region. The Kaiser Permanente Southern California medical region comprises 14 medical centers with over 80 urologists. A database was initiated to assess quality of life outcomes of patients diagnosed with localized prostate cancer.

9) This paper studied automated de-identification of clinical narrative text using natural language processing (NLP)-based methods. The specific aims were (1) to evaluate a state-of-the-art NLP-based approach to automatically de-identify a large set of diverse clinical notes for all HIPAA (Health Insurance Portability and Accountability Act)-defined protected health information (PHI) elements and (2) to measure the impact of de-identification on the performance of information extraction (IE) algorithms executed on the de-identified documents. In addition, we hope that our study—by contrasting the performance of human and automated de-identification—will shape policy expectations.

Background and significance
The importance of information included in narrative clinical text of the electronic health record (EHR) is gaining increasing recognition as a critical component of computerized decision support, quality improvement, and patient safety.1 ,2 In an August, 2011 JAMA editorial, Jha discusses the promises of the EHR, emphasizing the importance of NLP as an enabling tool for accessing the vast information residing in EHR notes.3 NLP could extract information from clinical free-text to fashion decision rules or represent clinical knowledge in a standardized format.4–6 Patient safety and clinical research could also benefit from information stored in text that is not available in either structured EHR entries or administrative data.7–9

However, the 1996 HIPAA privacy rule requires that before clinical text can be used for research, either (1) all PHI should be removed through a process of de-identification, (2) a patient's consent must be obtained, or (3) the institutional review board should grant a waiver of consent.10 Studies have shown that requesting consent reduces participation rate, and is often infeasible when dealing with large populations.11 ,12 Even if a waiver is granted, documents that include PHI should be tracked to prevent unauthorized disclosure. On the other hand, de-identification removes the requirements for consent, waiver, and tracking and facilitates clinical NLP research, and consequently, the use of information stored in narrative EHR notes.

Several studies have used NLP for removing PHI from medical documents.13 Rule-based methods14–23 make use of dictionaries and manually designed rules to match PHI patterns in the texts. They often lack generalizability and require both time and skill for creating rules, but perform better for rare PHI elements. Machine-learning-based methods,24–34 on the other hand, automatically learn to detect PHI patterns based on a set of examples and are more generalizable, but require a large set of manually annotated examples. Systems using a combination of both approaches usually tend to obtain the best results.13 ,35 Overall, the best systems report high recall and precision, often >90%, and sometimes as high as 99%. Nevertheless, no study has evaluated the performance of automated de-identification for all PHI classes.13 Important items are often ignored—in particular, ages >89,15 ,16 ,18 ,24 ,25 geographic locations,15 ,16 ,24 ,26 institution and contact information,16 ,24 ,26 dates, and IDs.16 ,24 Furthermore, systems should ideally be evaluated on a large scale, including the diverse document types of the EHRs, to have a good idea of their accuracy and generalizability. However, most systems use only one or two document types for evaluation, such as pathology reports,16 ,17 ,19 ,20 ,26 discharge summaries,23 ,25 ,27–30 ,34 nursing progress notes,23 ,34 outpatient follow-up notes,22 or medical message boards.33 Some of them were only evaluated on documents with synthetic patient PHI (manually de-identified documents re-identified with fake PHI).27–30 Very few systems have been evaluated on more than two note types.14 ,15 ,24 ,32 Only a handful of studies provide details on over-scrubbing (non-PHI wrongly identified as PHI) and none of them investigate the effect of de-identification on subsequent IE tasks.13 It is indeed possible that de-identification has an adverse effect on IE accuracy.13 Over-scrubbing errors could overlap with useful information—for example, if a disease name is erroneously recognized as a person name it will be removed and lost to subsequent IE application. Second, NLP techniques such as part-of-speech tagging and parsing may be less effective on modified text.

In this paper, we examine some of the gaps of the literature and conduct de-identification experiments on a large set and wide variety of clinical notes (over 22 different types), using real PHI data (as opposed to resynthesized data), studying all classes of PHI and measuring the impact of de-identification on a subsequent IE task. We also illustrate the strength of automatic de-identification by comparing human and system performances.

10) In the biomedical domain, the rapid adoption of Electronic Health Records (EHR) with the parallel growth of narrative data in electronic form, along with the needs for improved quality of care and reduced medical errors are both strong incentives for the development of Natural Language Processing (NLP) (sometimes called Medical Language Processing in this domain). Much of the available clinical data are in narrative form as a result of transcription of dictations, direct entry by providers, or use of speech recognition applications. This free-text form is convenient to express concepts and events, but is difficult for searching, summarization, decision-support, or statistical analysis. To reduce errors and improve quality control, coded data are required; this is where NLP, and more precisely Information Extraction (IE), is needed as explained below. IE typically requires some "pre-processing" such as spell checking, document structure analysis, sentence splitting, tokenization, word sense disambiguation, part-of-speech tagging, and some form of parsing. Contextual features like negation, temporality, and event subject identification are crucial for accurate interpretation of the extracted information. Several different techniques can be used to extract information, from simple pattern matching to complete processing methods based on symbolic information and rules or based on statistical methods and machine learning. The information extracted can then be linked to concepts in standard terminologies and used for coding. The information can also be used for decision support and to enrich the EHR itself. Biosurveillance, biomedical research, text mining, and automatic terminology management can also benefit from information extraction. Finally, automatic de-identification of textual documents also uses the extraction of personal information before its removal or replacement. We review all these uses of information extraction in this paper. This review focuses on research about information extraction from narrative documents stored in the EHR and published after 1995, with an emphasis on recent publications. Previous research on this topic is described in a review by Spyns [1]. Research on information extraction from the biomedical literature is not discussed in this paper, but is well described in reviews by Cohen et al. [2] and by Zweigenbaum et al. [3].

